
## Calendar

## 1. The Hadoop ecosystem

Describes the crucial building blocks to handle the dramatic growth of data in the enterprise.

Starting with a cronological context, we will cover the limit of vertical growing
of Information Systems. We will present the advantages of distributed, redondant
systems for Massive Parallel Processing and the new paradigms they introduce.

## 2. HDFS and MapReduce

Implement a distributed algorithm using the MapReduce pattern.

In this session, we will present MapReduce pattern, the Google's Algorithm
for batch processing.
We will also present HDFS, a distributed and redondant FileSystem.

## 3. YARN

Present YARN, the architectural center of Hadoop

We will present in this session YARN, the third and last fundamental brick of
Hadoop framework: the scheduler. We will see how it can ensure scheduling,
load balancing, and work-preserving restarts.

## 4. Pig

Present Pig, a scripting platform for processing

We will use Apache Pig interact with data stored in the cluster. Apache Pig allows
to write complex MapReduce transformations using a simple scripting language called Pig Latin.

## 5. Hive, MR and Tez

Present Hive, The standard for SQL queries in Hadoop.

With Hive, we will use SQL to query up-to petabytes of data.
We will also learn how to optimize your query through model design,
compression and data formatting.

## 6. ETL (extract, transform, load)

Use Sqoop, Flume and Oozie to place the session 3 algorithm inside a larger workflow.

## 7. HBase

Present HBase: A NoSQL database on top of HDFS

Build a short demo with the fast column family store as a backend.

## 8. Spark

Present Spark: In-memory compute for Data Science

Apache Spark brings fast, in-memory data processing to Hadoop for ETL, Machine Learning
and Data Science.

## Notes

All courses will take place in "Labo Linux User".
