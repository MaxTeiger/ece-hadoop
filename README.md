
# Syllabus

## Introduction

Apache Hadoop is evolving as the Big Data platform on top of which multiple building
blocks are being developed. By the end of the course, students will be familiar to this
large and growing ecosystem. We start to learn how to composed distributed programs using
the Map Reduce paradigm before using higher level processing languages. We then cover the
complementary tasks of the data analyst and learn how to leverage some of the most popular
softwares of the Hadoop platform. Finally, we will explore the fields of statistics,
pattern mining and data visualisation to grasp the job of talented data scientist.

## Requirements

This course is best suited for student familiar to SQL and database systems. Knowledge in
Java is required. Being confortable with Linux and Git is a plus. Prior knowledge of
Apache Hadoop is not required.

## Outline

1.  The Hadoop ecosystem
2.  HDFS and Map Reduce
3.  Advanced Map Reduce
4.  ETL (extract, transform, load)
5.  Hive and Pig
6.  HBase
7.  Workflow with Oozie and Cascalog
8.  Data scientist, an introduction to Mahout
9.  Build a recommendation engine

## Bibliography/webography

No book is required. We will learn how to retrieve up-to-date information from the wikis,
the source code and the various blogs.

