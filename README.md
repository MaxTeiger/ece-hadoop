
# Syllabus

This lecture was originally designed for 10 weeks, but can be resized if needed.
The syllabus will be presented in English but lessons can be taught in both French
or English.

## Introduction

Apache Hadoop is evolving as the Big Data platform on top of which multiple building
blocks are being developed. By the end of the course, students will be familiar to this
large and growing ecosystem.
We firstly cover the 3 bricks of Apache Hadoop Framework: the filesystem (HDFS),
the processing pattern and its API (MR), and the resource manager YARN.
We then cover the complementary tasks of the data analyst and learn how to leverage
some of the most popular softwares that are used on top of the Hadoop platform.
Finally, we will experiment functional programming through Spark.

## Objectives

Students will learn:

*   Distributed Systems: pros and cons, associated paradigms
*   Massively Parallel Processing
*   Design a Big Data solution on top of Hadoop framework
*   Functional Programming

## Requirements

This course is best suited for student familiar with programming and database
systems. Knowledge in Java and SQL is required. Being confortable with Linux,
Git and Maven is a plus.
Prior knowledge of Distributed Systems, Apache Hadoop, NoSQL, or functionnal
programming is not necessary.

## Outline

1.  The Hadoop ecosystem
2.  HDFS and MapReduce
3.  MapReduce and YARN
4.  Pig & Hive
5.  ETL (Extract, Transform, Load)
6.  HBase
7.  Spark
8.  Kafka
9.  Lambda Architecture
10. Final Exam

## Bibliography/webography

No book is required. A course material will be provided (presentation slides),
and students will learn how-to retrieve up-to-date information
from internet (wikis, articles, blogs, source code).
